{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:(245, 460, 460, 4), x_valid:(63, 460, 460, 4)\n",
      "y_train:(245,), y_valid:(63,)\n",
      "　　縦　　　横　　　チャネル数\n",
      "460 460 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Activation, concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import sys\n",
    "from utils import save_model_viz, save_weights, save_hist, plot_hist\n",
    "\n",
    "from keras.models import model_from_yaml\n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "RUN_ID = \"5\"\n",
    "# RUN_ID = sys.argv[1]\n",
    "\n",
    "x_train = np.load(\"npy/x_train\" + RUN_ID + \".npy\")\n",
    "y_train = np.load(\"npy/y_train\" + RUN_ID + \".npy\")\n",
    "x_valid = np.load(\"npy/x_valid\" + RUN_ID + \".npy\")\n",
    "y_valid = np.load(\"npy/y_valid\" + RUN_ID + \".npy\")\n",
    "\n",
    "print(\"x_train:{}, x_valid:{}\".format(x_train.shape, x_valid.shape))\n",
    "print(\"y_train:{}, y_valid:{}\".format(y_train.shape, y_valid.shape))\n",
    "\n",
    "print(\"　　縦　　　横　　　チャネル数\")\n",
    "print(x_train.shape[1],x_train.shape[2],x_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 458, 458, 16)      592       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 229, 229, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 227, 227, 8)       1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 75, 75, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 73, 73, 32)        2336      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 5, 5, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 33,945\n",
      "Trainable params: 33,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 245 samples, validate on 63 samples\n",
      "Epoch 1/100\n",
      "245/245 [==============================] - 49s 199ms/step - loss: 0.6786 - acc: 0.6245 - val_loss: 0.6752 - val_acc: 0.6190\n",
      "Epoch 2/100\n",
      "245/245 [==============================] - 40s 165ms/step - loss: 0.6696 - acc: 0.6245 - val_loss: 0.6685 - val_acc: 0.6190\n",
      "Epoch 3/100\n",
      "245/245 [==============================] - 31s 128ms/step - loss: 0.6635 - acc: 0.6245 - val_loss: 0.6634 - val_acc: 0.6190\n",
      "Epoch 4/100\n",
      "245/245 [==============================] - 32s 131ms/step - loss: 0.6577 - acc: 0.6245 - val_loss: 0.6589 - val_acc: 0.6190\n",
      "Epoch 5/100\n",
      "245/245 [==============================] - 31s 128ms/step - loss: 0.6528 - acc: 0.6245 - val_loss: 0.6550 - val_acc: 0.6190\n",
      "Epoch 6/100\n",
      "245/245 [==============================] - 32s 131ms/step - loss: 0.6479 - acc: 0.6245 - val_loss: 0.6519 - val_acc: 0.6190\n",
      "Epoch 7/100\n",
      "245/245 [==============================] - 30s 123ms/step - loss: 0.6448 - acc: 0.6245 - val_loss: 0.6492 - val_acc: 0.6190\n",
      "Epoch 8/100\n",
      "245/245 [==============================] - 30s 121ms/step - loss: 0.6416 - acc: 0.6245 - val_loss: 0.6451 - val_acc: 0.6190\n",
      "Epoch 9/100\n",
      "245/245 [==============================] - 32s 131ms/step - loss: 0.6377 - acc: 0.6245 - val_loss: 0.6418 - val_acc: 0.6190\n",
      "Epoch 10/100\n",
      "245/245 [==============================] - 32s 131ms/step - loss: 0.6332 - acc: 0.6245 - val_loss: 0.6362 - val_acc: 0.6190\n",
      "Epoch 11/100\n",
      "245/245 [==============================] - 36s 147ms/step - loss: 0.6299 - acc: 0.6245 - val_loss: 0.6306 - val_acc: 0.6190\n",
      "Epoch 12/100\n",
      "245/245 [==============================] - 33s 136ms/step - loss: 0.6237 - acc: 0.6245 - val_loss: 0.6261 - val_acc: 0.6190\n",
      "Epoch 13/100\n",
      "245/245 [==============================] - 31s 127ms/step - loss: 0.6186 - acc: 0.6245 - val_loss: 0.6210 - val_acc: 0.6190\n",
      "Epoch 14/100\n",
      "245/245 [==============================] - 33s 133ms/step - loss: 0.6146 - acc: 0.6245 - val_loss: 0.6154 - val_acc: 0.6190\n",
      "Epoch 15/100\n",
      "245/245 [==============================] - 32s 130ms/step - loss: 0.6100 - acc: 0.6286 - val_loss: 0.6107 - val_acc: 0.6190\n",
      "Epoch 16/100\n",
      "245/245 [==============================] - 31s 128ms/step - loss: 0.6010 - acc: 0.6245 - val_loss: 0.6021 - val_acc: 0.6190\n",
      "Epoch 17/100\n",
      "245/245 [==============================] - 31s 127ms/step - loss: 0.5915 - acc: 0.6245 - val_loss: 0.5901 - val_acc: 0.6190\n",
      "Epoch 18/100\n",
      "245/245 [==============================] - 31s 127ms/step - loss: 0.5802 - acc: 0.6571 - val_loss: 0.5795 - val_acc: 0.6984\n",
      "Epoch 19/100\n",
      "245/245 [==============================] - 32s 132ms/step - loss: 0.5704 - acc: 0.7184 - val_loss: 0.5646 - val_acc: 0.6984\n",
      "Epoch 20/100\n",
      "245/245 [==============================] - 32s 131ms/step - loss: 0.5535 - acc: 0.7102 - val_loss: 0.5509 - val_acc: 0.6508\n",
      "Epoch 21/100\n",
      "245/245 [==============================] - 30s 123ms/step - loss: 0.5395 - acc: 0.6612 - val_loss: 0.5362 - val_acc: 0.6667\n",
      "Epoch 22/100\n",
      "245/245 [==============================] - 29s 119ms/step - loss: 0.5186 - acc: 0.7265 - val_loss: 0.5118 - val_acc: 0.7778\n",
      "Epoch 23/100\n",
      "245/245 [==============================] - 31s 126ms/step - loss: 0.5057 - acc: 0.9020 - val_loss: 0.4973 - val_acc: 0.9365\n",
      "Epoch 24/100\n",
      "245/245 [==============================] - 33s 134ms/step - loss: 0.4866 - acc: 0.9755 - val_loss: 0.4705 - val_acc: 0.8571\n",
      "Epoch 25/100\n",
      "245/245 [==============================] - 30s 122ms/step - loss: 0.4583 - acc: 0.8449 - val_loss: 0.4667 - val_acc: 0.7460\n",
      "Epoch 26/100\n",
      "245/245 [==============================] - 30s 123ms/step - loss: 0.4467 - acc: 0.7755 - val_loss: 0.4314 - val_acc: 0.8095\n",
      "Epoch 27/100\n",
      "245/245 [==============================] - 31s 125ms/step - loss: 0.4142 - acc: 0.9388 - val_loss: 0.4010 - val_acc: 0.9524\n",
      "Epoch 28/100\n",
      "245/245 [==============================] - 31s 127ms/step - loss: 0.3938 - acc: 0.9551 - val_loss: 0.3765 - val_acc: 0.9365\n",
      "Epoch 29/100\n",
      "245/245 [==============================] - 30s 123ms/step - loss: 0.3640 - acc: 0.9224 - val_loss: 0.3619 - val_acc: 0.8889\n",
      "Epoch 30/100\n",
      "245/245 [==============================] - 29s 120ms/step - loss: 0.3473 - acc: 0.8735 - val_loss: 0.3324 - val_acc: 0.8889\n",
      "Epoch 31/100\n",
      "245/245 [==============================] - 31s 127ms/step - loss: 0.3073 - acc: 0.9633 - val_loss: 0.2968 - val_acc: 0.9524\n",
      "Epoch 32/100\n",
      "245/245 [==============================] - 34s 138ms/step - loss: 0.2857 - acc: 0.9796 - val_loss: 0.2693 - val_acc: 0.9524\n",
      "Epoch 33/100\n",
      "245/245 [==============================] - 32s 131ms/step - loss: 0.2499 - acc: 0.9633 - val_loss: 0.2377 - val_acc: 0.9524\n",
      "Epoch 34/100\n",
      "245/245 [==============================] - 32s 132ms/step - loss: 0.2255 - acc: 0.9673 - val_loss: 0.2103 - val_acc: 0.9683\n",
      "Epoch 35/100\n",
      "245/245 [==============================] - 31s 128ms/step - loss: 0.1916 - acc: 0.9633 - val_loss: 0.1947 - val_acc: 0.9365\n",
      "Epoch 36/100\n",
      "245/245 [==============================] - 32s 129ms/step - loss: 0.1771 - acc: 0.9714 - val_loss: 0.1710 - val_acc: 0.9683\n",
      "Epoch 37/100\n",
      "245/245 [==============================] - 34s 137ms/step - loss: 0.1523 - acc: 0.9755 - val_loss: 0.1770 - val_acc: 0.9365\n",
      "Epoch 38/100\n",
      "245/245 [==============================] - 32s 129ms/step - loss: 0.1538 - acc: 0.9673 - val_loss: 0.1482 - val_acc: 0.9524\n",
      "Epoch 39/100\n",
      "245/245 [==============================] - 31s 126ms/step - loss: 0.1266 - acc: 0.9796 - val_loss: 0.1358 - val_acc: 0.9683\n",
      "Epoch 40/100\n",
      "245/245 [==============================] - 31s 128ms/step - loss: 0.1185 - acc: 0.9796 - val_loss: 0.1266 - val_acc: 0.9524\n",
      "Epoch 41/100\n",
      "245/245 [==============================] - 32s 133ms/step - loss: 0.1060 - acc: 0.9755 - val_loss: 0.1169 - val_acc: 0.9683\n",
      "Epoch 42/100\n",
      "245/245 [==============================] - 31s 126ms/step - loss: 0.0978 - acc: 0.9755 - val_loss: 0.1100 - val_acc: 0.9683\n",
      "Epoch 43/100\n",
      "245/245 [==============================] - 35s 141ms/step - loss: 0.0883 - acc: 0.9796 - val_loss: 0.1057 - val_acc: 0.9683\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 38s 155ms/step - loss: 0.0826 - acc: 0.9878 - val_loss: 0.1038 - val_acc: 0.9683\n",
      "Epoch 45/100\n",
      "245/245 [==============================] - 33s 134ms/step - loss: 0.0805 - acc: 0.9755 - val_loss: 0.1077 - val_acc: 0.9524\n",
      "Epoch 46/100\n",
      "245/245 [==============================] - 28s 116ms/step - loss: 0.0772 - acc: 0.9755 - val_loss: 0.0930 - val_acc: 0.9683\n",
      "Epoch 47/100\n",
      "245/245 [==============================] - 30s 123ms/step - loss: 0.0683 - acc: 0.9918 - val_loss: 0.0907 - val_acc: 0.9683\n",
      "Epoch 48/100\n",
      "245/245 [==============================] - 32s 130ms/step - loss: 0.0650 - acc: 0.9837 - val_loss: 0.0851 - val_acc: 0.9683\n",
      "Epoch 49/100\n",
      "245/245 [==============================] - 34s 140ms/step - loss: 0.0605 - acc: 0.9837 - val_loss: 0.0858 - val_acc: 0.9524\n",
      "Epoch 50/100\n",
      "245/245 [==============================] - 33s 133ms/step - loss: 0.0600 - acc: 0.9837 - val_loss: 0.0796 - val_acc: 0.9683\n",
      "Epoch 51/100\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3])))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.012))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = Adam(lr=8e-5),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "save_model_viz(RUN_ID, model)\n",
    "hist = model.fit(x_train, y_train, epochs=100, batch_size=48,\n",
    "                 verbose=1, validation_data=(x_valid, y_valid))\n",
    "\n",
    "save_weights(RUN_ID, model)\n",
    "save_hist(RUN_ID, hist)\n",
    "plot_hist(RUN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
